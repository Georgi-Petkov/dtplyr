---
title: "Translation"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{translation}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Introduction

This vignette shows the details of how dtplyr translates dplyr expressions into [data.table](https://github.com/Rdatatable/data.table/wiki) code. If you see places where you think I could generate better data.table code, please let me know!

```{r setup, message = FALSE}
library(dtplyr)
library(data.table)
library(dplyr)
```

# The basics

To get started, I'll create a simple lazy frame. The actual data doesn't matter here since we're just looking at the translation:

```{r}
df <- data.frame(a = integer(), b = integer(), c = integer(), d = integer())
dt <- lazy_dt(df)
```

When we print it out, it tells us that it's a local data table with four rows. It also prints the call that dtplyr will evaluate when we execute the lazy table. In this case it's very simple: 

```{r}
dt
```

If we just want to see the generated code, you can use `show_query()`. I'll use that a lot in this vignette.

```{r}
dt %>% show_query()
```


# Simple verbs

Many dplyr verbs have a straightforward translation to either the `i` or `j` component of `[.data.table`. 


## `i`

`filter()` and `arrange()` become elements of `i`:

```{r}
dt %>% arrange(a, b, c) %>% show_query()
dt %>% filter(b == c) %>% show_query()
dt %>% filter(b == c, c == d) %>% show_query()
```

## `j`

`select()`, `rename()`, `summarise()` and `transmute()` all become elements of `j`:

```{r}
dt %>% select(a:b) %>% show_query()
dt %>% rename(x = a, y = b) %>% show_query()
dt %>% summarise(a = mean(a)) %>% show_query()
dt %>% transmute(a2 = a * 2) %>% show_query()
```

`mutate()` also uses the `j` component with data.table's special `:=` operator:

```{r}
dt %>% mutate(a2 = a * 2, b2 = b * 2) %>% show_query()
```

Note that dplyr doesn't modifies the input data (unless you set `immutable = FALSE`), so here it automatically `copy()`s the input data.table. 

`mutate()` allows to refer to variables that you just created. data.tables `:=` doesn't support that out of the box, so we automatically chain together as many `[` as needed:

```{r}
dt %>% mutate(a2 = a * 2, b2 = b * 2, a4 = a2 * 2) %>% show_query()
```

`transmute()` works similarly:

```{r}
dt %>% transmute(a2 = a * 2, b2 = b * 2, a4 = a2 * 2) %>% show_query()
```

## Grouping

Just like in dplyr, `group_by()` doesn't do anything by itself, but instead modifies the operation of downstream verbs. This generally just involves using the `by` argument:

```{r}
dt %>% group_by(a) %>% summarise(b = mean(b)) %>% show_query()
```

The primary exception is grouped `filter()`, which requires the use of `.SD` ()

```{r}
dt %>% group_by(a) %>% filter(b < mean(b)) %>% show_query()
```

Unlike the data.frame backend, `group_by()` does not sort the output in group order by default. If you want this behaviour, you can use `key_by()` instead:

```{r}
dt %>% key_by(a) %>% summarise(b = mean(b)) %>% show_query()
```

Because this does one upfront sort, it should generate more efficient code when performing repeated actions on the same groups.

## Distinct

`distinct()` is translated to some form of `unique()`:

```{r}
dt %>% distinct() %>% show_query()
dt %>% distinct(a, b) %>% show_query()
dt %>% distinct(a, b, .keep_all = TRUE) %>% show_query()
```

`distinct()` on a computed column uses an intermediate step:

```{r}
dt %>% distinct(c = a + b) %>% show_query()
dt %>% distinct(c = a + b, .keep_all = TRUE) %>% show_query()
```

# Combinations

dtplyr tries to generate generate data.table code as close to what you'd write by hand as possible, as this tends to unlock data.tables tremendous speed. For example, if you `filter()` and then `select()`, dtplyr generates a single `[`:

```{r}
dt %>% filter(a == 1) %>% select(-a) %>% show_query()
```

And similarly for filtering and summarising:

```{r}
dt %>% 
  group_by(a) %>% 
  filter(b < mean(b)) %>% 
  summarise(c = max(c)) %>% 
  show_query()
```

Note however, that `select()`ing and then `filter()`ing must generate two separate calls to `[`, because data.table evaluates `i` before `j`.

```{r}
dt %>% select(-a) %>% filter(a == 1) %>% show_query()

```

Note that `filter()` and `mutate()` can't be combined because `dt[a == 1, .(b2 := b * 2)]` modifies the selected rows in place.

However, dtplyr does strive to avoid needless copies, so it won't explicitly copy if there's already an implicit copy produced by `[`, `head()` or similar:

```{r}
dt %>% filter(x == 1) %>% mutate(a2 = a * 2, b2 = b * 2) %>% show_query()
```

Over time, as I learn more about data.table, I hope to expand the set of these simplifications.

# Joins

dtplyr converts mutating joins to `merge()`:

```{r}
dt2 <- lazy_dt(data.frame(a = 1))

dt %>% left_join(dt2, by = "a") %>% show_query()
dt %>% right_join(dt2, by = "a") %>% show_query()
dt %>% inner_join(dt2, by = "a") %>% show_query()
dt %>% full_join(dt2, by = "a") %>% show_query()
```

I don't currently convert left joins to the more idiomatic `dt[dt2]` because I haven't yet figured out how to handle the `suffixes` argument. This is a shame because there's a big advantage of the `dt[dt2]` form: you can combine it with a `j` argument for efficient summaries, e.g. `dt[dt2, sum(x * y)]`.

Anti-joins are easy to translate because data.table has a specific form for them:

```{r}
dt %>% anti_join(dt2, by = "a") %>% show_query()
```

Semi joins are little more complex:

```{r}
dt %>% semi_join(dt2, by = "a") %>% show_query()
```

# Performance

There are two components to the performance of dtplyr: how long it takes to generate the translation, and how well translation performs. Given my exploration so far, I'm reasonably confident that we're generating high-quality data.table code, so most of the cost should be in the translation itself. 

The following code briefly explores the performance of a few different translations. A signficant amount of work is done by the dplyr verbs, so we benchmark the whole process. Note that dtplyr run-time scales with the complexity of the pipeline, not the size of the data, so these timings should apply regardless of the size of the underlying data. (The only exception is use of `mutate()` will also generate a single copy of the input data.)

```{r}
bench::mark(
  filter = dt %>% filter(a == b, c == d),
  mutate = dt %>% mutate(a = a * 2, a4 = a2 * 2, a8 = a4 * 2) %>% show_query(),
  summarise = dt %>% group_by(a) %>% summarise(b = mean(b)) %>% show_query(),
  check = FALSE
)[1:6]
```

These translations all take less than a millisecond, which suggests that the performance overhead of dtplyr should be negligible. 


